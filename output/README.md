# Output Directory

This directory contains generated intermediate files and results from the pipeline.

## Generated Files (Auto-created when running `python run.py`)

### Core Files (Auto-generated by pipeline)

- **`vocab.pkl`** (Pickle)
  - Word-to-index vocabulary mapping
  - Generated by: Stage 1 (Vocabulary Building)
  - Size: ~250 KB

- **`embeddings.npy`** (NumPy array)
  - GloVe word vectors (97,806 ¡Á 50)
  - Generated by: Stage 4 (GloVe Embedding Training)
  - Size: ~8 MB

- **`cooc.pkl`** (Pickle)
  - Word co-occurrence matrix
  - Generated by: Stage 3 (Co-occurrence Matrix)
  - Size: ~97 MB (can be deleted after embeddings are trained)

### Training/Validation Split (Stage 2)

- **`train_texts.pkl`** - 90% of training data (~1.8M samples)
- **`train_labels.pkl`** - Corresponding labels
- **`val_texts.pkl`** - 10% validation data (~200K samples)
- **`val_labels.pkl`** - Corresponding labels
- Total size: ~180 MB

### Final Output

- **`submission.csv`** - Test predictions (10,000 rows)
  - Format: `id,prediction` where prediction is -1 or 1
  - Generated by: Stage 6 (Test Prediction)
  - Size: ~84 KB

## Total Size

When fully populated: ~300 MB

## Cleaning Up (Optional)

To save disk space, you can delete non-essential files after the pipeline completes:

```bash
# Keep only essential files for reproducibility
rm cooc.pkl train_texts.pkl train_labels.pkl val_texts.pkl val_labels.pkl
```

This leaves only:
- `vocab.pkl` (~250 KB)
- `embeddings.npy` (~8 MB)  
- `submission.csv` (~84 KB)
- Total: ~8 MB

## Regeneration

All files are auto-generated by `python run.py`. To regenerate from scratch:

```bash
# Clear output directory
rm -rf *

# Run pipeline (takes 30-60 minutes)
cd ..
python run.py
```

The pipeline will automatically regenerate all necessary files.
